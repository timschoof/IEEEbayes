---
output: html_document
---

### Background

Speech Reception Thresholds (in noise) using IEEE sentences. 

Two groups: 

- young adults without much noise exposure history
- middle-aged adults with quite a bit of noise exposure history

Four conditions (2x2): 

- two stimulus levels (40 and 80 dB SPL)
- either both the target and background noise were diotic (N~0~S~0~), or the target signal was inverted in polarity in one ear (N~0~S~$\pi$~) leading to a phase disparity across the ears

### Hypotheses

```{r setup, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
library(brms)
library(tidyverse)
library(tidybayes)
library(bayesplot)
library(GGally)
library(here)
```

### The data

uLevs = mean SNR (i.e. SRT) <br />
sdLevs = standard deviation SNR

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# read in data
iee <- read.csv(here("IEEEsummaries.csv"),header = TRUE)

# turn dB SPL variable into a factor
iee$dBSPL <- as.factor(iee$dBSPL)
# create group variable
iee <- iee %>%
  mutate(group = paste0(substr(listener,1,1))) %>% 
  mutate(group = fct_rev(as.factor(group))) %>% 
  select(listener, group, dBSPL, manipulation, uLevs, sdLevs)

head(iee)
```

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# plot SRTs
group.labs <- c("Young", "Middle Aged")
names(group.labs) <- c("Y", "M")

iee %>%
  ggplot(aes(x = factor(manipulation), y = uLevs, colour = dBSPL)) +
  facet_grid(. ~ group, 
             labeller = labeller(group = group.labs)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(size = 3, alpha = 0.2, position = position_jitterdodge()) +
  ylim(-14,3) +
  theme_bw() +
  scale_fill_manual(values=c("#00CC99","#CC0066")) +
  labs(x="", y = "SRT (dB)")+
  scale_x_discrete(labels=c("inverted" = expression("N"[0]*"S"[pi]), "none" = expression("N"[0]*"S"[0]))) + 
  guides(colour=guide_legend(title="Level (dB SPL)"))
```

### Bayesian analysis

#### Step 1: Begin with an "empty" model with varying intercepts

Questions:

* Should I standardize the outcome measure as well as the predictors?
* How should I assess the model at this stage?

I am creating an index variable for the listener variable. Note that I am not standardizing the outcome variable, instead I will specify the priors in dB.

Based on my PhD data (IEEEs in steady-state and amplitude modulated speech-shaped noise for young and older adults), I expect the overall mean to be -5 dB and the sd to be 1.5 dB.

```{r}
d <- iee %>% 
  mutate(uLevs = uLevs) %>% 
  mutate(listener = as.numeric(listener))
```

Specify the model as follows: 

SRT ~ Normal(mu, sigma) <br />
mu = a[listener] <br />
a[listener] ~ Normal(a_bar, a_sigma) <br />
a_bar ~ Normal(-5,1.5) <br />
a_sigma ~ cauchy(0,1) <br />
sigma ~ cauchy(0,1) <br />

Question: 

* Why would you use a half-cauchy distribution as opposed to an exponential or half-normal? I've heard that the cauchy distribution assumes medium-large effects, not small ones.
* Should I add a `1 +` for my intercept in the model?

```{r, eval = FALSE}
# specify varying intercept only model
brms_fmla <- brmsformula(uLevs ~ 1 + (1 | listener))

# specify priors
priors <- c(
  set_prior("normal(-5,1.5)",  class = "Intercept"),
  set_prior("cauchy(0,1)",  class = "sd"),
  set_prior("cauchy(0,1)",  class = "sd", coef = "Intercept", group = "listener")
)

# compile and run model
prior_only.mod <- brm(
  brms_fmla,
  data = d,
  family = "gaussian",
  prior = priors,
  inits = 0,
  iter = 2000,
  warmup = 1000,
  chains = 2,
  cores = 2,
  sample_prior = "only",
  seed = 42,
  control = list(max_treedepth = 10,
                 adapt_delta = 0.8)
)

save(prior_only.mod, file = here("prior_only.RDATA"))
```

```{r, echo = FALSE}
load(here("prior_only.RDATA"))
summary(prior_only.mod)
```

Questions:

* How would I go about interpreting this? 
* Would I need to look at any of this at this stage, or would I just do a prior predictive check and plot the results?

```{r, fig.cap="Prior predictive check: density plot showing priors (yrep) and SRTs (y)."}
# prior predictive check
ppc_dens_overlay(y = as.vector(d$uLevs), 
                 yrep = t(predict(prior_only.mod, draws=25)[,1])
                 )
```

This looks reasonable. It's not perfect, but it's a prior, it doesn't need to be. The data can do the rest. At least this is in the right ballpark, suggesting I didn't do something obviously stupid (yet). 


From https://www.rensvandeschoot.com/tutorials/brms-started/:
We see that the intercept (mean) is -4.98 and that the credible interval ranges from -7.80 to -2.13. In the brms output, not the variance of the first and second level is given, but instead the standard deviation. So, if we want to calculate the Intraclass correlation (ICC) we need to do this ourselves. We can use of the following code to calculate the ICC. This function will also indicate if 0 is included in the 95% CCI of the ICC. 

https://www.theanalysisfactor.com/the-intraclass-correlation-coefficient-in-mixed-models/

```{r}
hyp <- "sd_listener__Intercept^2 / (sd_listener__Intercept^2 + sigma^2) = 0"
hypothesis(prior_only.mod, hyp, class = NULL)
```

It just includes 0, so a multilevel model may not be warranted? But it probably won't hurt.


#### Step 2: Start adding predictor variables

Let's start building the model up a bit more by adding predictor variables. I will standardize predictors and create index variables.

Predictors:

* manipulation: the effect of inverting the polarity of the speech across the ears. The difference between the two conditions (inverted and not inverted) is the binaural intelligibility level difference (BILD)
* dBSPL: the stimulus level (40 or 80 dB SPL)
* group: young or middle-aged

Create an index variable for the 'manipulation' variable, where 'none' (i.e. not inverted) = 1, and 'inverted' = 2.  

We will need to come up with a better estimate for the prior, based on the literature, but for now I'll just assume an effect of 'manipulation' (i.e. BILD) of 3 dB with a standard deviation of 1 dB. Since 1 = none, and inverted = 2, I will use a negative mean, because SRTs are expected to decrease (i.e. improve) when the polarity of the speech is inverted in one ear. 

Question:

* Should I create an index variable for the dBSPL variable (it only has two levels, so they are like ordered categories), or shall I standardize it (underlyingly it's a continuous predictor)?

For now I have decided to create an index variable for the dBSPL predictor since there are only two levels. 40 dB SPL = 1, 80 dB SPL = 2. I'm guessing that the effect of stimulus level is going to be 3 dB, with performance improving at higher levels. Therefore, the prior has a mean of -3 dB.

I'm creating an index variable for group, where 'young' = 1, and 'middle-aged' = 2. I expect SRTs to be higher (i.e. poorer) for the middle-aged group, so I'm specifying the prior with a positive mean. I'm just guessing at this point that the effect is going to be pretty small, say 1 dB.


```{r}
d <- iee %>% 
  mutate(listener = as.numeric(listener)) %>%  
  mutate(manipulation = as.numeric(fct_rev(as.factor(manipulation))),
         dBSPL = as.numeric(dBSPL),
         group = as.numeric(group))
```

Specify the model as follows: 

SRT ~ Normal(mu, sigma) <br />
mu = a[listener] + bM * manipulation + bdB * dBSPL + bG * group <br />
a[listener] ~ Normal(a_bar, a_sigma) <br />
a_bar ~ Normal(-5,1.5) <br />
a_sigma ~ cauchy(0,1) <br />
bM ~ Normal(-3, 1) <br />
bdB ~ Normal(-3, 1) <br />
bG ~ Normal(1, 1) <br />
sigma ~ cauchy(0,1) <br />

To figure out:

* Add interactions 
* Add random slopes
* Could I use measurement error (SD) for IEEEs in my model? I've seen something like this in the Statistical Rethinking book

```{r, eval = FALSE}
# specify varying intercept & manipulation effect model
brms_fmla <- brmsformula(uLevs ~ manipulation + dBSPL + group + (1 | listener))

# specify priors
priors <- c(
  set_prior("normal(-5,1.5)",  class = "Intercept"),
  set_prior("normal(-3,1)",  class = "b", coef = "manipulation"),
  set_prior("normal(-3,1)",  class = "b", coef = "dBSPL"),
  set_prior("normal(1,1)",  class = "b", coef = "group"),
  set_prior("cauchy(0,1)",  class = "sd"),
  set_prior("cauchy(0,1)",  class = "sd", coef = "Intercept", group = "listener")
)

# compile and run model
full.mod <- brm(
  brms_fmla,
  data = d,
  family = "gaussian",
  prior = priors,
  inits = 0,
  iter = 5000,
  warmup = 2000,
  chains = 4,
  cores = 4,
  sample_prior = TRUE,
  seed = 42,
  control = list(max_treedepth = 10,
                 adapt_delta = 0.8)
)

save(full.mod, file = here("fullModel.RDATA"))
```

```{r, echo = FALSE}
load(here("fullModel.RDATA"))
summary(full.mod)
```

```{r}
#to get the Stan code:
  Model_Stan_Code <- stancode(full.mod)
  writeLines(Model_Stan_Code, "fullModel.stan")
  
#  and you'll definitely want:
stanD <- standata(full.mod)
```

Looking at the stan data, the intercept is always 1, why? And where does this come from in the code? And then after that all predictors are centered? Interesting.


Questions:

* Am I interpreting this correctly?
* What's the difference between Family specific parameters and group-level effects? 
* What does the population-level intercept refer to?
* What other things should I look at in this table? Rhat looks ok.

`Group-level effects: sd(Intercept)`: remaining unexplained variability among participants? This has changed quite a bit compared to the intercept-only model.
`Population-level effects`: I'm not sure what the intercept refers to here anymore. It's not the overall mean. Presumably the others are the effects of polarity inversion (manipulation), stimulus level (dBSPL), and group.

#### Step 3: Visualize the results

Questions:

* How do I evaluate the model?
* What should I visualize?

I'm not entirely sure what to visualize exactly, so I'm just trying a few things that seem sensible.

First, let's see what's in this model.

```{r}
get_variables(full.mod)
```

Next, let's turn this into a sensible data frame for plotting. <p style="color:red"> Wait, I don't think I'm actually using this data frame! What format should the data be in?</p> 

```{r}
full <- full.mod %>%
  spread_draws(b_Intercept, b_manipulation, b_group, b_dBSPL, r_listener[listenerID,term]) 
  
head(full)
```

Let's start with plotting the results that we looked at before in table form (the population level effects).

I'm going to start with creating a data fram that combines the data and the draws from the posterior fit. 

Question:

* Is there an easy way to go from the indexed variables back to the original values?

```{r}
# 
draws <- d %>%
  modelr::data_grid(listener, manipulation, dBSPL, group) %>%
  add_fitted_draws(full.mod) %>% 
  select(-.chain, -.iteration) 

head(draws)
```

Questions:

* What should I look at?
* How should I plot it? My plots can definitely be improved.
* Should I just look at the effects or also at the individuals?

'Let's plot the posterior draws (What's this called?) for the two groups, where 1 = young, 2 = middle-aged:

```{r}
draws %>%  
  ggplot(aes(x = .value, y = group)) +
  stat_halfeyeh()
```

For the two manipulation conditions, where 1 = none, 2 = inverted:

```{r}
draws %>%  
  ggplot(aes(x = .value, y = manipulation)) +
  stat_halfeyeh()
```

Stimulus level, where 1 = 40 dB SPL, 2 = 80 dB SPL: 

```{r}
draws %>%  
  ggplot(aes(x = .value, y = dBSPL)) +
  stat_halfeyeh()
```

Other things I'd like to look at:

* Difference between groups, manipulations, stimulus levels. Not sure how to plot that. The data frames are a pain to manipulate for some reason.
* Whatever I need to do for a proper posterior check. Can / should I plot things with the data?


Another thing I've seen being plotted, but I'm not sure what it means:
```{r}
pairs(full.mod,
      off_diag_args = list(size = 1/5, alpha = 1/5))
```

And I figured, let's look at WAIC and LOO, without really knowing what to do with it:
```{r}
full.mod <- add_criterion(full.mod, c("waic", "loo"))

full.mod$waic
full.mod$loo
```

A separate question is whether the model ran correctly. Let's visualize the chains.

```{r}
# extract the posterior samples
post <- posterior_samples(full.mod, add_chain = T)
# plot the traces
mcmc_trace(post, regex_pars = "b_")
```

This looks good, nothing crazy going on.

### Data visualisation brms tutorial
https://www.rensvandeschoot.com/tutorials/brms-started/

```{r}
library(ggmcmc)
full.mod.t <- ggs(full.mod) # the ggs function transforms the brms output into a longformat tibble, that we can use to make different types of plots.

# make sure to specify this correctly: fixed[4,3:4]
ggplot(filter(full.mod.t, Parameter == "b_group", Iteration > 1000), aes(x = value))+
  geom_density(fill = "orange", alpha = .5)+
  geom_vline(xintercept = 0, col = "red", size = 1)+ 
  geom_vline(xintercept = summary(full.mod)$fixed[4,3:4], col = "blue", linetype = 2)+
  theme_light()+
  labs(title = "Posterior Density of Regression Coefficient for Group")
```

Question: what do the CI values refer to? Are they 95% credible intervals? Not confidence intervals, right?

### Add a random slope

Based on the pairs plot, where it looked like there was a correlation between the intercept and the slopes of manipulation, dBSPL, and group. I'm going to add a random slope for dBSPL to start with. Nesting participants within group might be a good idea too at some point. 

It might make more sense to choose different random slopes, this is just so I can figure out how this works.


```{r}
d <- iee %>% 
  mutate(listener = as.numeric(listener)) %>%  
  mutate(manipulation = as.numeric(fct_rev(as.factor(manipulation))),
         dBSPL = as.numeric(dBSPL),
         group = as.numeric(group))
```


I don't know why this 1+ stuff is necessary, or not, but I'm going to put it in for now. I can change this when I figure out what it does. I mean, it changes the sd and sigma, but why?

LKJ: prior for the correlation matrix (between intercepts and slopes). Value of 2 (or anything above 1, really) means that extreme correlations are less likely. 

```{r, eval = FALSE}
# specify varying intercept & manipulation effect model
brms_fmla <- brmsformula(uLevs ~ 1 + manipulation + dBSPL + group + (1 + dBSPL | listener))

# specify priors
priors <- c(
  set_prior("normal(-5,1.5)",  class = "Intercept"),
  set_prior("normal(-3,1)",  class = "b", coef = "manipulation"),
  set_prior("normal(-3,1)",  class = "b", coef = "dBSPL"),
  set_prior("normal(1,1)",  class = "b", coef = "group"),
  set_prior("cauchy(0,1)",  class = "sd"),
  set_prior("cauchy(0,1)",  class = "sd", coef = "Intercept", group = "listener"),
  set_prior("lkj(2)", class = "cor")
)

# compile and run model
randomslope.mod <- brm(
  brms_fmla,
  data = d,
  family = "gaussian",
  prior = priors,
  inits = 0,
  iter = 5000,
  warmup = 2000,
  chains = 4,
  cores = 4,
  sample_prior = TRUE,
  seed = 42,
  control = list(max_treedepth = 10,
                 adapt_delta = 0.8)
)

save(randomslope.mod, file = here("RandomSlopeModel.RDATA"))
```

```{r, echo = FALSE}
load(here("RandomSlopeModel.RDATA"))
summary(randomslope.mod, WAIC = TRUE)
```

Not sure how to decide whether to include the random slope or not. The 95% CI does not include 0, so I guess keep it? Even if we could toss it out, if it's close to 0, it wouldn't do anything anyway, so it would be fine. 

### Go all out model!

```{r}
d <- iee %>% 
  mutate(listener = as.numeric(listener)) %>%  
  mutate(manipulation = as.numeric(fct_rev(as.factor(manipulation))),
         dBSPL = as.numeric(dBSPL),
         group = as.numeric(group))
```


```{r, eval = FALSE}
# specify varying intercept & manipulation effect model
brms_fmla <- brmsformula(uLevs ~ 1 + manipulation + dBSPL + group + 
                           manipulation:group +
                           dBSPL:group +
                           manipulation:dBSPL:group +
                           (1 + dBSPL | listener))

# specify priors
priors <- c(
  set_prior("normal(-5,1.5)",  class = "Intercept"),
  set_prior("normal(-3,1)",  class = "b", coef = "manipulation"),
  set_prior("normal(-3,1)",  class = "b", coef = "dBSPL"),
  set_prior("normal(1,1)",  class = "b", coef = "group"),
  set_prior("cauchy(0,1)",  class = "sd"),
  set_prior("cauchy(0,1)",  class = "sd", coef = "Intercept", group = "listener"),
  set_prior("lkj(2)", class = "cor")
)

# compile and run model
AllOut.mod <- brm(
  brms_fmla,
  data = d,
  family = "gaussian",
  prior = priors,
  inits = 0,
  iter = 5000,
  warmup = 2000,
  chains = 4,
  cores = 4,
  sample_prior = TRUE,
  seed = 42,
  control = list(max_treedepth = 10,
                 adapt_delta = 0.8)
)

save(AllOut.mod, file = here("AllOutModel.RDATA"))
```

```{r, echo = FALSE}
load(here("AllOutModel.RDATA"))
summary(AllOut.mod)
```

Plot stuff 


https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf


```{r}
hypothesis(fit1, "Intercept - age > 0", class = "sd", group = "patient")

# In accordance with this finding,theEvid.Ratioshows that the hypothesis being tested (i.e.,Intercept - age > 0) is about68 times more likely than the alternative hypothesisIntercept - age < 0.  It is importantto note that this kind of comparison is not easily possible when applying frequentist methods,because in this case only point estimates are available for group-level standard deviations andcorrelations.
```

Should I include a random slope of dBSPL?
```{r}
fit2 <- update(AllOut.mod, formula. = ~ . - (1 + dBSPL|listener) + (1|listener))
LOO(AllOut.mod, fit2)
```



### More questions

* How would I best explain the difference in inference between Bayesian and frequentist stats?
* What if you have unequal number of measures per participant, partly on purpose, because you decided to rerun a test occasionally? I think that's fine, the multilevel model will deal with that. My collaborator wants to compute a median across multiple measurements.
* Are there fewer assumptions because you can just model things the way you want?
* What do you do with outliers? Check something in WAIC or LOO or something?
* What do you do with missing data? Bayesian imputation?




